{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "t9Exep0pobsa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-huggingfaceNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [14 lines of output]\n",
      "      + c:\\Users\\rishabh.p\\Documents\\Python Projects\\.venv\\Scripts\\python.exe C:\\Users\\rishabh.p\\AppData\\Local\\Temp\\pip-install-dybon75z\\numpy_74e32f46b970444ca40cdaf394c6a23b\\vendored-meson\\meson\\meson.py setup C:\\Users\\rishabh.p\\AppData\\Local\\Temp\\pip-install-dybon75z\\numpy_74e32f46b970444ca40cdaf394c6a23b C:\\Users\\rishabh.p\\AppData\\Local\\Temp\\pip-install-dybon75z\\numpy_74e32f46b970444ca40cdaf394c6a23b\\.mesonpy-bc5u5k8g -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\rishabh.p\\AppData\\Local\\Temp\\pip-install-dybon75z\\numpy_74e32f46b970444ca40cdaf394c6a23b\\.mesonpy-bc5u5k8g\\meson-python-native-file.ini\n",
      "      The Meson build system\n",
      "      Version: 1.2.99\n",
      "      Source dir: C:\\Users\\rishabh.p\\AppData\\Local\\Temp\\pip-install-dybon75z\\numpy_74e32f46b970444ca40cdaf394c6a23b\n",
      "      Build dir: C:\\Users\\rishabh.p\\AppData\\Local\\Temp\\pip-install-dybon75z\\numpy_74e32f46b970444ca40cdaf394c6a23b\\.mesonpy-bc5u5k8g\n",
      "      Build type: native build\n",
      "      Project name: NumPy\n",
      "      Project version: 1.26.4\n",
      "      Activating VS 17.13.1\n",
      "      The system cannot find the file specified.\n",
      "      \n",
      "      ..\\meson.build:1:0: ERROR: Compiler cl cannot compile programs.\n",
      "      \n",
      "      A full log can be found at C:\\Users\\rishabh.p\\AppData\\Local\\Temp\\pip-install-dybon75z\\numpy_74e32f46b970444ca40cdaf394c6a23b\\.mesonpy-bc5u5k8g\\meson-logs\\meson-log.txt\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: langchain_core in c:\\users\\rishabh.p\\documents\\python projects\\.venv\\lib\\site-packages (0.3.40)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\rishabh.p\\documents\\python projects\\.venv\\lib\\site-packages (0.3.7)\n",
      "Collecting langchain_chroma\n",
      "  Downloading langchain_chroma-0.2.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\rishabh.p\\documents\\python projects\\.venv\\lib\\site-packages (0.3.18)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\rishabh.p\\documents\\python projects\\.venv\\lib\\site-packages (1.10.0)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
      "Collecting serpapi\n",
      "  Downloading serpapi-0.1.5-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.3.5-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\rishabh.p\\documents\\python projects\\.venv\\lib\\site-packages (from langchain-huggingface) (0.29.1)\n",
      "Collecting sentence-transformers>=2.6.0 (from langchain-huggingface)\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tokenizers>=0.19.1 (from langchain-huggingface)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting transformers>=4.39.0 (from langchain-huggingface)\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\rishabh.p\\documents\\python projects\\.venv\\lib\\site-packages (from langchain_core) (0.3.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\rishabh.p\\documents\\python projects\\.venv\\lib\\site-packages (from langchain_core) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rishabh.p\\documents\\python projects\\.venv\\lib\\site-packages (from langchain_core) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\rishabh.p\\documents\\python projects\\.venv\\lib\\site-packages (from langchain_core) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\rishabh.p\\documents\\python projects\\.venv\\lib\\site-packages (from langchain_core) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\rishabh.p\\documents\\python projects\\.venv\\lib\\site-packages (from langchain_core) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\rishabh.p\\documents\\python projects\\.venv\\lib\\site-packages (from langchain_core) (2.10.6)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in c:\\users\\rishabh.p\\documents\\python projects\\.venv\\lib\\site-packages (from langchain_openai) (1.64.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\rishabh.p\\documents\\python projects\\.venv\\lib\\site-packages (from langchain_openai) (0.9.0)\n",
      "Collecting numpy<2.0.0,>=1.26.2 (from langchain_chroma)\n",
      "  Downloading numpy-1.26.4.tar.gz (15.8 MB)\n",
      "     ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "     ---------- ----------------------------- 4.2/15.8 MB 26.3 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 12.1/15.8 MB 31.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  15.7/15.8 MB 26.5 MB/s eta 0:00:01\n",
      "     --------------------------------------- 15.8/15.8 MB 24.8 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-huggingface langchain_core langchain_openai langchain_chroma langchain_community faiss-cpu pypdf langchainhub serpapi google-search-results langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViCriuQC0Pza"
   },
   "source": [
    "If you are using Jupyter notebook, follow the below instructions. Else skip this step and go to next step\n",
    "\n",
    "**Open .env file in this folder and observe that we have configured OPENAI_API_KEY. Replace it with your own key or key given by me**\n",
    "\n",
    "The Code in the below cell will load the .env file and set environment variables.\n",
    "\n",
    "**Write the code in the below cell and execute it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "TCGuUu3l0Pzc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5735,
     "status": "ok",
     "timestamp": 1734401138838,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "nf2Ul_yoovVY"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Install google-colab package\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m userdata\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Set OpenAI API key\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Install google-colab package\n",
    "\n",
    "\n",
    "from google.colab import userdata\n",
    "\n",
    "# Set OpenAI API key\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = userdata.get('LANGCHAIN_TRACING_V2')\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
    "os.environ[\"SERPAPI_API_KEY\"] = userdata.get('SERPAPI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zO5RUZlO0Pzd"
   },
   "source": [
    "# Understanding tools\n",
    "\n",
    "Tools are interfaces that an agent, chain, or LLM can use to interact with the world\n",
    "\n",
    "Tool consists of several components:\n",
    "\n",
    "**name (str), is required and must be unique within a set of tools provided to an agent\\\n",
    "description (str),  it is used by an agent to determine tool use\\\n",
    "args_schema (Pydantic BaseModel), is optional**\n",
    "\n",
    "# Defining tool using @tool Decorator\n",
    "\n",
    "**Understand how we are defining a tool using @tool decorator.\\\n",
    "Execute the below code and observe the input**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3613,
     "status": "ok",
     "timestamp": 1731888748828,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "jZBvlRGcpUHP",
    "outputId": "032c07e9-d634-4585-a238-648a6ac40d4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multiplies a and b.\n",
      "{'a': {'title': 'A'}, 'b': {'title': 'B'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='add', description='Adds a and b.', args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x000001F3E67C7F60>),\n",
       " StructuredTool(name='multiply', description='Multiplies a and b.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x000001F3F745A480>),\n",
       " StructuredTool(name='subtract', description='Subtracts b from a.', args_schema=<class 'langchain_core.utils.pydantic.subtract'>, func=<function subtract at 0x000001F3E67C7CE0>)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a, b) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return int(a) + int(b)\n",
    "\n",
    "\n",
    "@tool\n",
    "def subtract(a, b) -> int:\n",
    "    \"\"\"Subtracts b from a.\"\"\"\n",
    "    return int(a) -int(b)\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a, b) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return int(a) * int(b)\n",
    "\n",
    "\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)\n",
    "tools = [add, multiply,subtract]\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEOlFEu10Pze"
   },
   "source": [
    "**You can also customize the tool name and JSON args by passing them into the tool decorators shown below**\n",
    "\n",
    "**Execute the below code and observe the result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 601,
     "status": "ok",
     "timestamp": 1731888908029,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "c-idICTT0Pze",
    "outputId": "b2b66683-4df7-4e44-a546-1aa54ed0ba95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='search-tool' description='Look up things online.' args_schema=<class '__main__.SearchInput'> return_direct=True func=<function search at 0x000001F3E621B920>\n",
      "search-tool\n",
      "Look up things online.\n"
     ]
    }
   ],
   "source": [
    "#from langchain.pydantic_v1 import BaseModel, Field\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"should be a search query\")\n",
    "\n",
    "\n",
    "@tool(\"search-tool\", args_schema=SearchInput, return_direct=True)\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Look up things online.\"\"\"\n",
    "    return \"LangChain\"\n",
    "\n",
    "print(search)\n",
    "print(search.name)\n",
    "print(search.description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UTT96Iz0Pzf"
   },
   "source": [
    "**You can create a tool using Structured tool as  shown below**\n",
    "\n",
    "**Execute the below code and observe the result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1731888910533,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "QEwKQlOc0Pzf",
    "outputId": "a6d055d1-bc81-4c9a-a6cd-d6834cde249c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='multiplytool', description='multiply numbers', args_schema=<class '__main__.MultiplyInput'>, return_direct=True, handle_tool_error=True, func=StructuredTool(name='multiply', description='Multiplies a and b.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x000001F3F745A480>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "from langchain.tools import  StructuredTool, tool\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MultiplyInput(BaseModel):\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "multiplytool = StructuredTool.from_function(\n",
    "    func=multiply,\n",
    "    name=\"multiplytool\",\n",
    "    description=\"multiply numbers\",\n",
    "    args_schema=MultiplyInput,\n",
    "    return_direct=True,\n",
    "    handle_tool_error=True\n",
    "\n",
    ")\n",
    "multiplytool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkXqxt5g0Pzf"
   },
   "source": [
    "# Let us use someexisting tools.\n",
    "\n",
    "Tavily can be used as a search tool.\n",
    "\n",
    "got to (https://tavily.com/), sign up and get the api key\n",
    "\n",
    "You have to set TAVILY_API_KEY as env variable.\n",
    "\n",
    "Open .env file and set TAVILY_API_KEY\n",
    "\n",
    "Understand the below code and execute it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 4740,
     "status": "ok",
     "timestamp": 1731888919204,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "wgsDJNdZ0Pzf",
    "outputId": "ba11d523-6b1e-4518-a3a1-423a77d7e597"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "\"SSLError(MaxRetryError(\\\"HTTPSConnectionPool(host='api.tavily.com', port=443): Max retries exceeded with url: /search (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1028)')))\\\"))\"\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get info from https://api.smith.langchain.com: LangSmithConnectionError('Connection error caused failure to GET /info in LangSmith API. Please confirm your internet connection. SSLError(MaxRetryError(\"HTTPSConnectionPool(host=\\'api.smith.langchain.com\\', port=443): Max retries exceeded with url: /info (Caused by SSLError(SSLCertVerificationError(1, \\'[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1028)\\')))\"))\\nContent-Length: None\\nAPI Key: lsv2_********************************************0a')\n",
      "Failed to batch ingest runs: langsmith.utils.LangSmithConnectionError: Connection error caused failure to POST https://api.smith.langchain.com/runs/batch in LangSmith API. Please confirm your internet connection. SSLError(MaxRetryError(\"HTTPSConnectionPool(host='api.smith.langchain.com', port=443): Max retries exceeded with url: /runs/batch (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1028)')))\"))\n",
      "Content-Length: 1338\n",
      "API Key: lsv2_********************************************0a\n",
      "post: trace=d2b61543-72c5-45ab-9768-d7fa08d97bad,id=d2b61543-72c5-45ab-9768-d7fa08d97bad\n",
      "Failed to batch ingest runs: langsmith.utils.LangSmithConnectionError: Connection error caused failure to POST https://api.smith.langchain.com/runs/batch in LangSmith API. Please confirm your internet connection. SSLError(MaxRetryError(\"HTTPSConnectionPool(host='api.smith.langchain.com', port=443): Max retries exceeded with url: /runs/batch (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1028)')))\"))\n",
      "Content-Length: 3895\n",
      "API Key: lsv2_********************************************0a\n",
      "post: trace=4fea5b82-122f-4f73-a8c0-8c79fb8d6e4b,id=4fea5b82-122f-4f73-a8c0-8c79fb8d6e4b\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "\n",
    "\n",
    "taviltysearch = TavilySearchResults(max_results=5)\n",
    "search_results = taviltysearch.invoke(\"Tell me about SivaPrasad Valluru\")\n",
    "#print(search_results)\n",
    "\n",
    "import json\n",
    "from IPython.display import Markdown\n",
    "json_content = json.dumps(search_results, indent=4)\n",
    "Markdown(f\"```json\\n{json_content}\\n```\")\n",
    "\n",
    "\n",
    "# If we want, we can create other tools.\n",
    "# Once we have all the tools we want, we can put them in a list that we will reference later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KR-np_Oj0Pzg"
   },
   "source": [
    "**Now, let us use model with tools and observe the respone from the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2342,
     "status": "ok",
     "timestamp": 1731888925012,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "yqgXB9Y20Pzg",
    "outputId": "168b1168-793b-4d7e-9de1-8cb66287e824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: Hello! How can I assist you today?\n",
      "ToolCalls: []\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "tools = [taviltysearch,add,subtract,multiply]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "response = llm_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2zhKggo0Pzg"
   },
   "source": [
    "**After executing above code, you might have observed that there are no tool calls.**\n",
    "\n",
    "**Now execute the below code and observe the tool calls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1731888928820,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "UjiUp2Z30Pzg",
    "outputId": "ab141439-a686-4169-8519-649f8575d1bc"
   },
   "outputs": [],
   "source": [
    "response = llm_with_tools.invoke([HumanMessage(content=\"Tell me about SivaPrasad Valluru\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHjKwjJp0Pzg"
   },
   "source": [
    "# Let us try to create our first agent manually\n",
    "\n",
    "\n",
    "**The core idea of agents is to use a language model to choose a sequence of actions to take. \\\n",
    "In chains, a sequence of actions is hardcoded (in code). \\\n",
    "In agents, a language model is used as a reasoning engine to determine which actions to take and in which order.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0m0s8hU0Pzg"
   },
   "source": [
    "**We need to create a function which takes List of tools , tool name and returns the matching tool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qUIAbwLSpcgP"
   },
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "from langchain.tools import Tool\n",
    "\n",
    "def find_tool_by_name(tools: List[Tool], tool_name: str) -> Tool:\n",
    "    for tool in tools:\n",
    "        if tool.name == tool_name:\n",
    "            return tool\n",
    "    raise ValueError(f\"Tool wtih name {tool_name} not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKj6Q-QU0Pzh"
   },
   "source": [
    "# Let us create  react  prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Azg5KxmN51F2"
   },
   "source": [
    "***Actual Prompt should be like below:***\n",
    "\n",
    "***Try the below prompt in open ai playground.***\n",
    "\n",
    "***Keep Stop Sequences as 'Observation'***\n",
    "\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "tavily_search_results_json - A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.\n",
    "add(a, b) -> int - Adds a and b.\n",
    "subtract(a, b) -> int - Subtracts b from a.\n",
    "multiply(a, b) -> int - Multiplies a and b.\n",
    "\n",
    "You must use only these tools, even if you can compute the response directly.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "\n",
    "Thought: consider what action to take\n",
    "\n",
    "Action: choose an action, which should be one of ['tavily_search_results_json', 'add', 'subtract', 'multiply']\n",
    "\n",
    "Action Input: provide the input for the chosen action\n",
    "\n",
    "Observation: note the result of the action\n",
    "\n",
    "... (this Thought/Action/Action Input/Observation cycle can repeat as needed)\n",
    "\n",
    "\n",
    "Thought: I now know the final answer\n",
    "\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: What is 2+3 multipled by 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M80zD-ls6Au3"
   },
   "source": [
    "**Execute the below code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1731888936221,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "ksSgSmMKprZg",
    "outputId": "20064cbe-e032-4cd9-dcab-4df9c92df93b"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools.render import render_text_description\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "    Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "    {tools}\n",
    "\n",
    "    You have to use these tools only even if u can compute the response directly\n",
    "\n",
    "    Use the following format:\n",
    "\n",
    "    Question: the input question you must answer\n",
    "    Thought: you should always think about what to do\n",
    "    Action: the action to take, should be one of [{tool_names}]\n",
    "    Action Input: the input to the action\n",
    "    Observation: the result of the action\n",
    "    ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "    Thought: I now know the final answer\n",
    "    Final Answer: the final answer to the original input question\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    Question: {input}\n",
    "    Thought: {agent_scratchpad}\n",
    "    \"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=template).partial(\n",
    "        tools=render_text_description(tools),\n",
    "        tool_names=\", \".join([t.name for t in tools]),\n",
    "    )\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srSnv4im0Pzh"
   },
   "source": [
    "**We want to log the prompt to LLM and response from LLM**\n",
    "\n",
    "**We can define callback handler as shown below**\n",
    "\n",
    "**Execute the below code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWXR_8yorh9I"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List\n",
    "\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.schema import LLMResult\n",
    "\n",
    "\n",
    "class AgentCallbackHandler(BaseCallbackHandler):\n",
    "    def on_llm_start(\n",
    "        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any\n",
    "    ) -> Any:\n",
    "        \"\"\"Run when LLM starts running.\"\"\"\n",
    "        print(f\"***Prompt to LLM was:***\\n{prompts[0]}\")\n",
    "        print(\"*********\")\n",
    "\n",
    "    def on_llm_end(self, response: LLMResult, **kwargs: Any) -> Any:\n",
    "        \"\"\"Run when LLM ends running.\"\"\"\n",
    "        print(f\"***LLM Response:***\\n{response.generations}\")\n",
    "        print(\"*********\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1731888944086,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "_JUrgeomtwM_",
    "outputId": "5007bdb1-4e3e-44f7-cb7a-7d2812301c91"
   },
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        model=\"gpt-4o-mini\",\n",
    "    #model=\"gpt-4-turbo\",\n",
    "       # model_kwargs={\"stop\": [\"\\nObservation\", \"Observation\"]},\n",
    "      #  callbacks=[AgentCallbackHandler()],\n",
    "       stop_sequences=[\"\\nObservation\", \"Observation\"],\n",
    "\n",
    "    )\n",
    "\n",
    "llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_steps = []\n",
    "agentchain = {\n",
    "            \"input\": lambda x: x[\"input\"],\n",
    "            \"agent_scratchpad\": lambda x: x[\"intermediate_steps\"]\n",
    "        } | prompt | llm\n",
    "\n",
    "agentchain.invoke(\n",
    "            {\n",
    "                \"input\": \"What is 2+3 multipled by 4\",\n",
    "                \"intermediate_steps\": intermediate_steps,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observe that we got AI Message as response and observe the content has action and action input.**\n",
    "\n",
    "**By using this text, we want to create an object of AgentAction.**\n",
    "\n",
    "**So, We can use ReActSingleInputOutputParse in the chain as shown below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1731888948794,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "g5ucdwrB0Pzh",
    "outputId": "a1b35b80-f053-45c9-ba76-896ef5f4f8f8"
   },
   "outputs": [],
   "source": [
    "from langchain.agents.output_parsers import ReActSingleInputOutputParser\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "\n",
    "intermediate_steps = []\n",
    "agentchain = (\n",
    "        {\n",
    "            \"input\": lambda x: x[\"input\"],\n",
    "            \"agent_scratchpad\": lambda x: x[\"intermediate_steps\"],\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | ReActSingleInputOutputParser()\n",
    "    )\n",
    "agentaction=agentchain.invoke(\n",
    "            {\n",
    "                \"input\": \"What is 2+3 multipled by 4\",\n",
    "                \"intermediate_steps\": intermediate_steps,\n",
    "            }\n",
    "        )\n",
    "\n",
    "agentaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that AgentAction object has log property which containes the entire text which we got in AIMessage\n",
    "\n",
    "We are adding a tuple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1OiyAnRi2e7_"
   },
   "outputs": [],
   "source": [
    "intermediate_steps.append((agentaction,5))\n",
    " # after we perform the given action 2+3, thre result is 5 passed as obervation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1731889071474,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "a2IENO9o2vRO",
    "outputId": "e37ff937-31a4-415d-c3e7-31d7c39f6346"
   },
   "outputs": [],
   "source": [
    "format_log_to_str(intermediate_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, once u understand what this function format_log_to_str is doing, modify the agent as below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_steps = []\n",
    "agent = (\n",
    "        {\n",
    "            \"input\": lambda x: x[\"input\"],\n",
    "            \"agent_scratchpad\": lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | ReActSingleInputOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPOj_d0m0Pzh"
   },
   "source": [
    "**Once Agent is invoked, it will return either AgentAction or AgentFinish object**\n",
    "\n",
    "**we need to run a loop which will continue until agent returns AgentFinish**\n",
    "\n",
    "**If agent returns AgentAction, we nned to get the  tool in AgentAction, Invoke it and add returned values as  Observation in intermediate_steps**\n",
    "\n",
    "**Understand the below code and execute it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6422,
     "status": "ok",
     "timestamp": 1731889437941,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "vbtB5HMouEhX",
    "outputId": "45ea82a2-ccec-4b24-afcb-d54282f16306"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m intermediate_steps\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(agent_step, AgentFinish):\n\u001b[1;32m----> 6\u001b[0m   agent_step: Union[AgentAction, AgentFinish] \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m      7\u001b[0m             {\n\u001b[0;32m      8\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is 2+5 multiplied by 4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintermediate_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m: intermediate_steps,\n\u001b[0;32m     10\u001b[0m             }\n\u001b[0;32m     11\u001b[0m         )\n\u001b[0;32m     12\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_step\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(agent_step, AgentAction):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.schema import AgentAction, AgentFinish\n",
    "\n",
    "agent_step = \"\"\n",
    "intermediate_steps=[]\n",
    "while not isinstance(agent_step, AgentFinish):\n",
    "  agent_step: Union[AgentAction, AgentFinish] = agent.invoke(\n",
    "            {\n",
    "                \"input\": \"What is 2+5 multiplied by 4\",\n",
    "                \"intermediate_steps\": intermediate_steps,\n",
    "            }\n",
    "        )\n",
    "  print(f\"{agent_step=}\")\n",
    "\n",
    "  if isinstance(agent_step, AgentAction):\n",
    "    tool_name = agent_step.tool\n",
    "    tool_to_use = find_tool_by_name(tools, tool_name)\n",
    "    tool_input = agent_step.tool_input\n",
    "    tool_input=tool_input.split(\",\")\n",
    "    if(len(tool_input)==1):\n",
    "      tool_input=tool_input[0]\n",
    "    print(f\"{tool_input=}\")\n",
    "    #tool_to_use.\n",
    "    #observation = tool_to_use.func(*tool_input)\n",
    "    observation = tool_to_use.invoke(tool_input)\n",
    "\n",
    "    print(f\" invoked the tool {tool_name = } on {tool_input=}. Result {observation=}\")\n",
    "\n",
    "    intermediate_steps.append((agent_step, str(observation)))\n",
    "\n",
    "    print(f\"intermediate_steps {intermediate_steps=}\")\n",
    "\n",
    "    if isinstance(agent_step, AgentFinish):\n",
    "        print(agent_step.return_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us try to create agents using predefined functions and use them\n",
    "\n",
    "\n",
    "Go to https://smith.langchain.com/hub/hwchase17/react and observe the prompt.\n",
    "\n",
    "We will be using this prompt in the below code\n",
    "\n",
    "What is the purpose of agent_scratchpad in the  prompt?\n",
    "\n",
    "Execute the below code\n",
    "\n",
    "Now let us create our first agent which can use tool calls to execute the tools and interact with LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using React Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langgraph.prebuilt import create_react_agent\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor,create_react_agent\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "agent = create_react_agent(llm=llm, tools=tools,prompt=prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    verbose=True,\n",
    "    max_iterations=20,\n",
    "    tools=tools,\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "response = agent_executor.invoke({\"input\": \"whats the weather in bangalore?\"})\n",
    "\n",
    "#response\n",
    "\n",
    "\n",
    "#for chunk in agent_executor.stream(\n",
    "#    {\"input\": \"whats the weather in sf?\"}\n",
    "#):\n",
    "#    print(chunk)\n",
    "#    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using tool calling agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import  create_tool_calling_agent\n",
    "from langchain.prompts import ChatPromptTemplate,HumanMessagePromptTemplate,MessagesPlaceholder\n",
    "from langchain.schema import SystemMessage\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessage(content=(\n",
    "            \"You are an AI .\"\n",
    "            \"You should not use tools parallelly \"\n",
    "            \"You should not make your own conclusions even if it is easy. instead use appropriate tools \"\n",
    "        )),\n",
    "\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "    ]\n",
    ")\n",
    "prompt\n",
    "\n",
    "agent = create_tool_calling_agent(llm=llm, tools=tools,prompt=prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    verbose=True,\n",
    "    max_iterations=20,\n",
    "    tools=tools,\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "print(f\"{tools}\")\n",
    "response = agent_executor.invoke({\"input\": \"tell me about sivaPrasad valluru  in 3 bullet points\"})\n",
    "\n",
    "\n",
    "#for chunk in agent_executor.stream(\n",
    "#    {\"input\": \"tell me about sivaPrasad valluru  in 3 bullet points\"}\n",
    "#):\n",
    "#    print(chunk)\n",
    "#    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5533,
     "status": "ok",
     "timestamp": 1731889447689,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "BOeyQcED8NY7",
    "outputId": "7ff2428c-261f-4935-8b57-b9084f3977a9"
   },
   "outputs": [],
   "source": [
    "pip install wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3IHtYRE0Pzh"
   },
   "source": [
    "**If we want to search in wikipedia, we can use WikipediaAPIWrapper as shown below**\n",
    "\n",
    "**Execute the below code and observe the result**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3083,
     "status": "ok",
     "timestamp": 1731889453270,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "xRmnDbp378zE",
    "outputId": "9ce4d75c-f714-4744-c2cf-4533d5e11862"
   },
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=1000)\n",
    "\n",
    "print(api_wrapper.run(\"Sachin Tendulkar\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGr7cfP50Pzi"
   },
   "source": [
    "**WikipediaAPIWrapper Cannot be used as a tool**\n",
    "\n",
    "**If you want to use it as a tool, u can use WikipediaQueryRun as shown below**\n",
    "\n",
    "**Execute the below code and observe the result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2181,
     "status": "ok",
     "timestamp": 1731889459065,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "pEEyN-4W0Pzi",
    "outputId": "e3262c14-16ad-4dd1-b2be-07dd0f6b1fd5"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from pydantic import BaseModel, Field\n",
    "#from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class WikiInputs(BaseModel):\n",
    "    \"\"\"Inputs to the wikipedia tool.\"\"\"\n",
    "\n",
    "    query: str = Field(\n",
    "        description=\"query to look up in Wikipedia, should be 3 or less words\"\n",
    "    )\n",
    "\n",
    "tool = WikipediaQueryRun(\n",
    "    name=\"wiki-tool\",\n",
    "    description=\"look up things in wikipedia\",\n",
    "    args_schema=WikiInputs,\n",
    "    api_wrapper=api_wrapper,\n",
    "    return_direct=True,\n",
    ")\n",
    "\n",
    "print(tool.run(\"Sachin Tendulkar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4600,
     "status": "ok",
     "timestamp": 1731889597276,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "KARVNYkrCrW0",
    "outputId": "d898fd55-57d7-4cf3-d45b-80d779189c4e"
   },
   "outputs": [],
   "source": [
    "pip install serpapi google-search-results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTEUiASt0Pzi"
   },
   "source": [
    "**If we want to search in Google, we can use SerpAPIWrapper as shown below**\n",
    "\n",
    "**Get key from https://serpapi.com/ and configure env variable with name  SERPAPI_API_KEY**\n",
    "\n",
    "**Execute the below code and observe the result**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2455,
     "status": "ok",
     "timestamp": 1731889602707,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "VyyW6AaH_r97",
    "outputId": "98721abf-2ce9-4a44-8618-bb231ebedd99"
   },
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "print(search.run(\"tell about SivaPrasad Valluru  in 5 bullet points. I want only info about him \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnI0DaT20Pzi"
   },
   "source": [
    "**To use SerpAPIWrapper as a tool, u can use the below code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2245,
     "status": "ok",
     "timestamp": 1731889617831,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "aE3I-0uVFjaz",
    "outputId": "599d41ae-1eb7-44d6-8677-c99a1f18b28a"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "tools=[]\n",
    "tools = load_tools([\"serpapi\"])\n",
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1731889626270,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "xBA933J3-pRL",
    "outputId": "5ed450a3-f476-46d8-a27c-3b65342525dd"
   },
   "outputs": [],
   "source": [
    "tools = [taviltysearch,add,subtract,multiply]  +tools\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etxcbnZj0Pzm"
   },
   "source": [
    "# Using SQL Database Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_lKRfnZ0Pzm"
   },
   "outputs": [],
   "source": [
    "pip install pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llw6oKDj0Pzm"
   },
   "source": [
    "If u want to connect to your mysql database,\n",
    "\n",
    "**Download sql from https://github.com/lerocha/chinook-database/releases/download/v1.4.5/Chinook_MySql.sql and execute it in your mysql db**\n",
    "\n",
    "**Change username and password in the below code and execute it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1784,
     "status": "ok",
     "timestamp": 1734401248721,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "_ZrzpsiI0Pzm",
    "outputId": "662a1e5f-28fe-4da5-da5a-7d83680fab27"
   },
   "outputs": [],
   "source": [
    "from langchain.sql_database import SQLDatabase\n",
    "\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook_Sqlite.sqlite\")\n",
    "\n",
    "#db=SQLDatabase.from_uri(f\"mysql+pymysql://root:root@localhost/chinook\",sample_rows_in_table_info = 3)\n",
    "\n",
    "\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "#print(db.run(\"SELECT * FROM Artist LIMIT 10;\"))\n",
    "\n",
    "# context = db.get_context()\n",
    "# print(list(context))\n",
    "# print(context[\"table_info\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 682,
     "status": "ok",
     "timestamp": 1734401341972,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "wlIAxAwC0Pzo",
    "outputId": "74fa9aac-5e68-4522-c2ef-d3151b147240"
   },
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm =  ChatOpenAI()\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(toolkit.get_tools())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XH1IzbvC0Pzo"
   },
   "source": [
    "**Use the below code to pull the prompt from langchain hub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1734401491581,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "N3vMx8esMDyf"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate,HumanMessagePromptTemplate,MessagesPlaceholder\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import AgentExecutor,create_tool_calling_agent\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessage(content=(\n",
    "            \"You are an AI .\"\n",
    "            \"You should not use tools parallelly \"\n",
    "            \"You should not make your own conclusions even if it is easy. instead use appropriate tools \"\n",
    "        )),\n",
    "\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "    ]\n",
    ")\n",
    "prompt\n",
    "\n",
    "agent = create_tool_calling_agent(llm=llm, tools=toolkit.get_tools(),prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2817,
     "status": "ok",
     "timestamp": 1734401506494,
     "user": {
      "displayName": "SivaPrasad Valluru",
      "userId": "03440549206981602615"
     },
     "user_tz": -330
    },
    "id": "a-FJnswIQ_cQ",
    "outputId": "2271d36d-2d4c-49ec-ae93-e6ba1a3a3ddf"
   },
   "outputs": [],
   "source": [
    "response = agent_executor.invoke({\"input\": \"which artist acted in maximum albums\"})\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
